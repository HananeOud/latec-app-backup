 1. Backend Core (~30 min)

  - server/app.py - Remove legacy endpoints, verify static serving
  - server/routers/agent.py - Clean up comments, verify handler registry extensibility
  - server/routers/chat.py - Check for old code paths
  - server/agents/handlers/databricks_endpoint.py - Remove failed attempt code, verify clean implementation

  Focus: Remove commented code, verify handler pattern is clean

  2. Backend Storage & Config (~15 min)

  - server/chat_storage.py - Verify matches documented behavior
  - server/config_loader.py - Check for hardcoded assumptions about deployment types
  - config/agents.json - Verify structure matches docs

  Focus: No hardcoded "databricks-endpoint" assumptions outside handlers

  3. Frontend Core (~30 min)

  - client/components/chat/ChatView.tsx - Remove debug logs, verify stream handling
  - client/app/page.tsx - Verify alert logic matches session-management.md
  - client/components/modals/TraceModal.tsx - Clean up, verify no MLflow API calls

  Focus: Remove console.logs, verify no dead code from old implementations

  4. Frontend Components (~15 min)

  - client/components/chat/MessageList.tsx - Check for old feedback code
  - client/components/chat/ChatInput.tsx - Verify agent selector works
  - client/components/modals/FeedbackModal.tsx - Verify optimistic UI

  Focus: Quick scan for legacy code

  5. Configuration & Build (~15 min)

  - client/next.config.ts - Verify static export config
  - .env.production - Check environment variables
  - pyproject.toml - Verify dependencies match usage

  Focus: No unused dependencies, correct build settings

  6. Documentation Consistency (~15 min)

  - Cross-check docs/features/*.md against actual code
  - Verify TODO.md matches reality
  - Check README has correct setup instructions

  Focus: Docs match implementation

  7. Security Scan (~15 min)

  - Check for exposed tokens/secrets
  - Verify no unsafe eval/exec
  - Check CORS settings
  - Verify input validation on endpoints

  Focus: Critical security issues only

  ---
  Execution Order

  1. Backend Core (most complex)
  2. Backend Storage (dependencies for frontend)
  3. Frontend Core (most complex)
  4. Frontend Components (quick wins)
  5. Config/Build (environment setup)
  6. Docs (verification)
  7. Security (final check)

  ---
  Output Per Section

  For each section, report:
  - âœ… Clean - No issues
  - âš ï¸ Minor - Comments/logs to remove, not breaking
  - âŒ Issue - Breaks extensibility, wrong implementation, security risk

---

## BACKEND ARCHITECTURE & TECHNICAL FLOW

### Application Entry Point

**Main Process:**
```bash
# Production (Databricks Apps) - from app.yaml
uvicorn server.app:app --host 0.0.0.0 --port 8000

# Development (Local)
uvicorn server.app:app --reload --host 0.0.0.0 --port 8000
```

**What happens on startup:**
1. Python imports `server/app.py`
2. **Module-level execution** (runs immediately on import):
   - `server/tracing.py` imported â†’ sets `mlflow.set_tracking_uri('databricks')` globally
   - `dotenv` loads `.env.local` (dev) or uses system env (prod)
   - `config_loader` singleton initialized â†’ loads all JSON configs from `/config`
   - `ChatStorage` singleton initialized â†’ creates empty in-memory storage
3. FastAPI `app` object created
4. Routers registered with `/api` prefix
5. Static file serving mounted (if `client/out/` exists)
6. Uvicorn starts HTTP server on port 8000

---

### Request Flow Diagram

**Development Mode:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER BROWSER                             â”‚
â”‚                   (http://localhost:3000)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEXT.JS DEV SERVER                            â”‚
â”‚                     (Port 3000)                                  â”‚
â”‚  â”œâ”€ Serves React app                                            â”‚
â”‚  â””â”€ Proxies /api/* â†’ http://localhost:8000/api/*               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ (Proxied API requests)
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UVICORN HTTP SERVER                           â”‚
â”‚                     (Port 8000)                                  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              FastAPI Application                        â”‚   â”‚
â”‚  â”‚              (server/app.py)                            â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Middleware Stack:                                      â”‚   â”‚
â”‚  â”‚  â””â”€ CORSMiddleware (allow_origins=['http://localhost:3000'])â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Route Resolution:                                      â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/health         â†’ health.router                â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/config/*       â†’ config.router                â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/invoke_endpoint â†’ agent.router                â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/log_assessment â†’ agent.router                 â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/chats/*        â†’ chat.router                  â”‚   â”‚
â”‚  â”‚  â””â”€ /* â†’ 404 (no static files in dev)                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Production Mode (Databricks Apps):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER BROWSER                             â”‚
â”‚         (https://my-app-xxxxx.databricksapps.com)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UVICORN HTTP SERVER                           â”‚
â”‚                     (Port 8000)                                  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              FastAPI Application                        â”‚   â”‚
â”‚  â”‚              (server/app.py)                            â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Middleware Stack:                                      â”‚   â”‚
â”‚  â”‚  â””â”€ CORSMiddleware (allow_origins=[])                  â”‚   â”‚
â”‚  â”‚     â†‘ Empty = same-origin only (most secure)           â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Route Resolution:                                      â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/health         â†’ health.router                â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/config/*       â†’ config.router                â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/invoke_endpoint â†’ agent.router                â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/log_assessment â†’ agent.router                 â”‚   â”‚
â”‚  â”‚  â”œâ”€ /api/chats/*        â†’ chat.router                  â”‚   â”‚
â”‚  â”‚  â””â”€ /*                  â†’ StaticFiles(directory='client/out')â”‚
â”‚  â”‚     â†‘ Serves Next.js static export (created by 'npm run build')â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼ (Example: POST /api/invoke_endpoint)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENT ROUTER                                 â”‚
â”‚              server/routers/agent.py                            â”‚
â”‚                                                                 â”‚
â”‚  @router.post('/invoke_endpoint')                              â”‚
â”‚  async def invoke_endpoint(options: InvokeEndpointRequest)     â”‚
â”‚                                                                 â”‚
â”‚  1. Generate client_request_id (req-xxxxx)                     â”‚
â”‚  2. Look up agent config via config_loader.get_agent_by_id()   â”‚
â”‚  3. Set MLflow experiment ID                                   â”‚
â”‚  4. Create MLflow trace (router trace for feedback linking):   â”‚
â”‚     â””â”€ mlflow.start_span() â†’ creates trace                     â”‚
â”‚     â””â”€ mlflow_client.set_trace_tag('client_request_id', ...)  â”‚
â”‚  5. Get deployment_type from agent config                      â”‚
â”‚  6. Look up handler class from DEPLOYMENT_HANDLERS registry    â”‚
â”‚  7. Instantiate handler (e.g., DatabricksEndpointHandler)      â”‚
â”‚  8. Call handler.invoke_stream() or handler.invoke()           â”‚
â”‚  9. Return StreamingResponse (SSE) or JSON                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               DEPLOYMENT HANDLER                                â”‚
â”‚     server/agents/handlers/databricks_endpoint.py              â”‚
â”‚                                                                 â”‚
â”‚  class DatabricksEndpointHandler(BaseDeploymentHandler)        â”‚
â”‚                                                                 â”‚
â”‚  async def invoke_stream():                                    â”‚
â”‚    1. Check ENV variable (development vs production)           â”‚
â”‚    2. Get Databricks credentials:                              â”‚
â”‚       - Development: DATABRICKS_HOST + DATABRICKS_TOKEN (PAT)  â”‚
â”‚       - Production: WorkspaceClient() (OAuth)                  â”‚
â”‚    3. Build request payload (Databricks Agent API format):     â”‚
â”‚       {'input': messages, 'stream': True}                      â”‚
â”‚    4. POST to https://{host}/serving-endpoints/{name}/invocationsâ”‚
â”‚    5. Stream response via httpx.AsyncClient.stream():          â”‚
â”‚       â”œâ”€ Emit client_request_id event first                    â”‚
â”‚       â”œâ”€ Forward each SSE line from Databricks                 â”‚
â”‚       â””â”€ Parse and validate JSON events                        â”‚
â”‚    6. Yield SSE-formatted chunks to client                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DATABRICKS MODEL SERVING                           â”‚
â”‚         (External - runs on Databricks infrastructure)         â”‚
â”‚                                                                 â”‚
â”‚  Agent Endpoint (e.g., "databricks-agent-01")                  â”‚
â”‚  â”œâ”€ Receives: {'input': [...messages], 'stream': True}        â”‚
â”‚  â”œâ”€ Executes: LangChain agent with tools                       â”‚
â”‚  â”œâ”€ Creates: MLflow trace (agent trace - separate from router) â”‚
â”‚  â””â”€ Streams: SSE events back to handler                        â”‚
â”‚                                                                 â”‚
â”‚  SSE Events Streamed:                                          â”‚
â”‚  â”œâ”€ response.output_text.delta (text chunks)                   â”‚
â”‚  â”œâ”€ response.output_item.done (function calls, final text)     â”‚
â”‚  â”œâ”€ trace.summary (trace metadata at end)                      â”‚
â”‚  â””â”€ [DONE] (end of stream)                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ (SSE stream flows back up the stack)
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENT BROWSER                               â”‚
â”‚              client/components/chat/ChatView.tsx                â”‚
â”‚                                                                 â”‚
â”‚  1. fetch('/api/invoke_endpoint')                              â”‚
â”‚  2. Read SSE stream with response.body.getReader()             â”‚
â”‚  3. Parse each 'data:' line as JSON event                      â”‚
â”‚  4. Handle events:                                             â”‚
â”‚     â”œâ”€ trace.client_request_id â†’ Store for feedback           â”‚
â”‚     â”œâ”€ response.output_text.delta â†’ Append to message         â”‚
â”‚     â”œâ”€ response.output_item.done â†’ Collect function calls     â”‚
â”‚     â””â”€ trace.summary â†’ Attach to message                      â”‚
â”‚  5. Save messages to backend: POST /api/chats/{id}/messages   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Feedback Flow

```
USER CLICKS THUMBS UP/DOWN
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /api/log_assessment              â”‚
â”‚  {                                     â”‚
â”‚    trace_id: "req-xxxxx",             â”‚  â† client_request_id
â”‚    agent_id: "databricks-agent-01",   â”‚
â”‚    assessment_value: true/false       â”‚
â”‚  }                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  server/routers/agent.py                                    â”‚
â”‚  @router.post('/log_assessment')                           â”‚
â”‚                                                             â”‚
â”‚  1. Get agent config â†’ mlflow_experiment_id                â”‚
â”‚  2. Call find_trace_for_feedback(client_request_id)        â”‚
â”‚     â”œâ”€ Search MLflow for router trace (by tag)             â”‚
â”‚     â”œâ”€ Check deployment_type from agent config             â”‚
â”‚     â””â”€ If 'databricks-endpoint':                           â”‚
â”‚         â””â”€ Call _find_databricks_agent_trace()             â”‚
â”‚             â””â”€ Time-proximity search (Â±2 seconds)           â”‚
â”‚             â””â”€ Find agent's server-side trace               â”‚
â”‚  3. mlflow.log_feedback(trace_id=agent_trace_id, ...)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Configuration Loading (Startup)

```
APPLICATION STARTS
        â”‚
        â–¼
server/app.py imports server/config_loader.py
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ConfigLoader.__init__()                 â”‚
â”‚  (runs on module import - singleton)     â”‚
â”‚                                          â”‚
â”‚  1. Locate config directory:             â”‚
â”‚     /config (relative to project root)   â”‚
â”‚  2. Load JSON files:                     â”‚
â”‚     â”œâ”€ app.json â†’ branding, dashboard    â”‚
â”‚     â”œâ”€ agents.json â†’ agent definitions   â”‚
â”‚     â””â”€ about.json â†’ about page content   â”‚
â”‚  3. Cache in memory                      â”‚
â”‚  4. Log: "âœ… Configuration loaded: N agents"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
Global singleton: config_loader
  â”œâ”€ .get_agent_by_id(id) â†’ Used by routers
  â”œâ”€ .agents_config â†’ All agents
  â””â”€ .app_config â†’ Branding/dashboard
```

---

### Chat Storage (In-Memory)

```
POST /api/chats (Create new chat)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  server/chat_storage.py                â”‚
â”‚  Global singleton: storage             â”‚
â”‚                                        â”‚
â”‚  storage.create(title, agent_id)      â”‚
â”‚  â”œâ”€ Check if 10 chats exist           â”‚
â”‚  â”œâ”€ If yes: Delete oldest (by updated_at)â”‚
â”‚  â”œâ”€ Create Chat object:               â”‚
â”‚  â”‚   {                                â”‚
â”‚  â”‚     id: "chat_xxxxx",              â”‚
â”‚  â”‚     title: "...",                  â”‚
â”‚  â”‚     agent_id: "...",               â”‚
â”‚  â”‚     messages: [],                  â”‚
â”‚  â”‚     created_at: now,               â”‚
â”‚  â”‚     updated_at: now                â”‚
â”‚  â”‚   }                                â”‚
â”‚  â””â”€ Store in self.chats dict          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
POST /api/chats/{id}/messages (Save messages after streaming)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  storage.add_message(chat_id, msg)    â”‚
â”‚  â”œâ”€ Append Message to chat.messages  â”‚
â”‚  â”œâ”€ Update chat.updated_at            â”‚
â”‚  â””â”€ Auto-generate title from 1st msg â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Environment Variable Flow

```
DEPLOYMENT MODE DETECTION
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ENV variable (set in .env.local or app.yaml)        â”‚
â”‚  â”œâ”€ ENV=development â†’ Local dev with PAT             â”‚
â”‚  â””â”€ ENV=production (default) â†’ Databricks Apps OAuthâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  server/agents/handlers/databricks_endpoint.py       â”‚
â”‚  get_databricks_credentials()                        â”‚
â”‚                                                      â”‚
â”‚  if env == 'development':                           â”‚
â”‚    â”œâ”€ Read DATABRICKS_HOST from os.getenv()        â”‚
â”‚    â”œâ”€ Read DATABRICKS_TOKEN from os.getenv()       â”‚
â”‚    â””â”€ Log: "ğŸ”§ Development mode - using PAT"       â”‚
â”‚  else:                                              â”‚
â”‚    â”œâ”€ from databricks.sdk import WorkspaceClient   â”‚
â”‚    â”œâ”€ w = WorkspaceClient() (auto OAuth)           â”‚
â”‚    â”œâ”€ Get host/token from w.config                 â”‚
â”‚    â””â”€ Log: "ğŸš€ Production mode - using OAuth"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Credentials used for all Databricks API calls:     â”‚
â”‚  â””â”€ POST {host}/serving-endpoints/{name}/invocationsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### CORS Configuration & Security

**Why CORS is Environment-Dependent:**

```
DEVELOPMENT MODE (ENV=development):
  â”œâ”€ Frontend: http://localhost:3000 (Next.js dev server)
  â”œâ”€ Backend:  http://localhost:8000 (FastAPI)
  â””â”€ Problem:  Different ports = different origins
      â””â”€ Solution: allow_origins=['http://localhost:3000']

PRODUCTION MODE (ENV=production):
  â”œâ”€ Frontend: Served by FastAPI from client/out/
  â”œâ”€ Backend:  Same FastAPI server
  â””â”€ Benefit:  Same origin = no CORS needed
      â””â”€ Solution: allow_origins=[] (most secure, same-origin only)
```

**Security Implications:**

| Configuration | Security | Use Case |
|---------------|----------|----------|
| `allow_origins=[]` | âœ… **Most Secure** | Production (same-origin) |
| `allow_origins=['http://localhost:3000']` | âš ï¸ Dev Only | Local development |
| `allow_origins=['*.databricksapps.com']` | âŒ **Insecure** | Allows ANY Databricks App to call your API |
| `allow_origins=['*']` | âŒ **Very Insecure** | Never use in production |

**Why wildcards are dangerous:**
- `*.databricksapps.com` would allow `https://malicious-app.databricksapps.com` to call your API
- An attacker could deploy a malicious Databricks App and steal user data via CSRF attacks
- Empty list `[]` means "only accept requests from the same domain", which is what you want

**Current Implementation (server/app.py:40-55):**
```python
env = os.getenv('ENV', 'production')
allowed_origins = ['http://localhost:3000'] if env == 'development' else []

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,  # Environment-aware
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

### Static File Serving (Dev vs Production)

**Development Mode:**
```
DEVELOPMENT SETUP:
  â”œâ”€ NO client/out/ directory exists (not built yet)
  â”œâ”€ Next.js dev server runs separately: cd client && npm run dev
  â”œâ”€ User accesses: http://localhost:3000
  â””â”€ FastAPI app.py startup:
      â””â”€ build_path.exists() = False
      â””â”€ Logs warning: "Next.js build directory not found"
      â””â”€ Does NOT mount StaticFiles
      â””â”€ All requests to FastAPI get 404 (except /api/* routes)

Next.js dev server handles:
  â”œâ”€ Serving React app with hot reload
  â”œâ”€ Proxying /api/* to http://localhost:8000
  â””â”€ Fast refresh for code changes
```

**Production Mode:**
```
PRODUCTION BUILD:
  1. cd client && npm run build
     â””â”€ Creates: client/out/ (Next.js static export)
     â””â”€ Contains: HTML, JS bundles, CSS, assets (all pre-compiled)

  2. FastAPI app.py startup:
     â””â”€ build_path.exists() = True (client/out/ found)
     â””â”€ app.mount('/', StaticFiles(directory='client/out', html=True))
     â””â”€ Logs: "Serving Next.js static files from client/out"

USER REQUEST:
  GET / or GET /chat or GET /about
        â”‚
        â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  FastAPI Route Resolution            â”‚
  â”‚  1. Check /api/* routes first        â”‚
  â”‚  2. If no match: StaticFiles handler â”‚
  â”‚     â””â”€ Serve from client/out/        â”‚
  â”‚        â”œâ”€ HTML files (index.html)    â”‚
  â”‚        â”œâ”€ JS bundles (pre-compiled)  â”‚
  â”‚        â”œâ”€ CSS files                  â”‚
  â”‚        â””â”€ Assets                     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Key difference: Static files are PRE-BUILT (no hot reload)
  â””â”€ All React code compiled at build time
  â””â”€ FastAPI just serves files (no processing)
```

**Code Implementation (server/app.py:60-68):**
```python
build_path = Path(".") / "client/out"
if build_path.exists():
    logger.info(f"Serving Next.js static files from {build_path}")
    app.mount("/", StaticFiles(directory=str(build_path), html=True), name="static")
else:
    logger.warning(
        f"Next.js build directory {build_path} not found. "
        "In development, run Next.js separately: cd client && npm run dev"
    )
```

---

### Summary: What Makes This Architecture Clean

âœ… **Single Entry Point**: `server/app.py` - one main, clear startup
âœ… **Router Pattern**: Endpoints organized by domain (agent, chat, config, health)
âœ… **Handler Pattern**: Deployment types abstracted, easy to extend
âœ… **Singleton Pattern**: config_loader, storage - loaded once, used everywhere
âœ… **Side-Effect Imports**: tracing.py - MLflow setup happens on import (intentional)
âœ… **ENV-Based Config**: Development vs Production detected cleanly
âœ… **CORS Security**: Environment-aware (localhost in dev, same-origin in prod)
âœ… **Static Serving**: Conditional mounting based on build directory existence
âœ… **No Circular Dependencies**: Clean import hierarchy
âœ… **FastAPI Auto-Docs**: Automatic OpenAPI/Swagger at `/docs`
